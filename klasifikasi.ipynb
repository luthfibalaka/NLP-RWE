{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download fasttext embedding (for first time)\n",
    "# import fasttext.util\n",
    "# fasttext.util.download_model('en', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setproctitle\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from transformers import set_seed\n",
    "from sentence_transformers.SentenceTransformer import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "set_seed(42, deterministic=True)\n",
    "setproctitle.setproctitle(\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"BLESS/train.tsv\", sep=\"\\t\", header=None, names=[\"kata1\",\"kata2\",\"relasi\"]).dropna().reset_index(drop=True)\n",
    "test = pd.read_csv(\"BLESS/test.tsv\", sep=\"\\t\", header=None, names=[\"kata1\",\"kata2\",\"relasi\"]).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_learned_embeddings(name: str):\n",
    "    fin = io.open(name, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.array(tokens[1:], dtype=float)\n",
    "    return data\n",
    "rwe_5_epochs = load_learned_embeddings('rwe_embeddings.txt')\n",
    "ft = fasttext.load_model('../cc.en.300.bin')\n",
    "embedding_model = SentenceTransformer('dunzhang/stella_en_1.5B_v5', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_stella():\n",
    "    representations = []\n",
    "    word1s: list[str] = train[\"kata1\"].to_list()\n",
    "    word2s: list[str] = train[\"kata2\"].to_list()\n",
    "    word1s_embeddings = embedding_model.encode(word1s, batch_size=256, show_progress_bar=True)\n",
    "    word2s_embeddings = embedding_model.encode(word2s, batch_size=256, show_progress_bar=True)\n",
    "\n",
    "    for i in range(len(train)):\n",
    "        word1_embed = word1s_embeddings[i]\n",
    "        word2_embed = word2s_embeddings[i]\n",
    "        pair_difference = np.subtract(word1_embed, word2_embed)\n",
    "        representations.append(pair_difference)\n",
    "\n",
    "    train['representation'] = representations\n",
    "    X_train = np.vstack(train['representation'])\n",
    "    y_train = train['relasi']\n",
    "\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_rwe():\n",
    "    representations = []\n",
    "    for i in range(len(train)):\n",
    "        word1_embedding = ft.get_word_vector(train[\"kata1\"][i])\n",
    "        word2_embedding = ft.get_word_vector(train[\"kata2\"][i])\n",
    "\n",
    "        word1_rwe = rwe_5_epochs.get(train[\"kata1\"][i], np.zeros(300,))\n",
    "        word2_rwe = rwe_5_epochs.get(train[\"kata2\"][i], np.zeros(300,))\n",
    "\n",
    "        pair_difference_ft = np.subtract(word1_embedding, word2_embedding)\n",
    "        pair_addition_rwe = np.multiply(word1_rwe, word2_rwe)\n",
    "        pair_multiplication_rwe = np.multiply(word1_rwe, word2_rwe)\n",
    "\n",
    "        pair_representation = np.concatenate((pair_difference_ft, pair_addition_rwe))\n",
    "        pair_representation = np.concatenate((pair_representation, pair_multiplication_rwe))\n",
    "\n",
    "        representations.append(pair_representation)\n",
    "\n",
    "    train['representation'] = representations\n",
    "    X_train = np.vstack(train['representation'])\n",
    "    y_train = train['relasi']\n",
    "\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_ft():\n",
    "    representations = []\n",
    "    for i in range(len(train)):\n",
    "        word1_embedding = ft.get_word_vector(train[\"kata1\"][i])\n",
    "        word2_embedding = ft.get_word_vector(train[\"kata2\"][i])\n",
    "        pair_representation = np.subtract(word1_embedding, word2_embedding)\n",
    "        representations.append(pair_representation)\n",
    "\n",
    "    train['representation'] = representations\n",
    "    X_train = np.vstack(train['representation'])\n",
    "    y_train = train['relasi']\n",
    "\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_stella_final():\n",
    "    representations = []\n",
    "    word1s: list[str] = train[\"kata1\"].to_list()\n",
    "    word2s: list[str] = train[\"kata2\"].to_list()\n",
    "    word1s_embeddings = embedding_model.encode(word1s, batch_size=256, show_progress_bar=True)\n",
    "    word2s_embeddings = embedding_model.encode(word2s, batch_size=256, show_progress_bar=True)\n",
    "\n",
    "    for i in range(len(train)):\n",
    "        word1_embed = word1s_embeddings[i]\n",
    "        word2_embed = word2s_embeddings[i]\n",
    "        word1_rwe = rwe_5_epochs.get(train[\"kata1\"][i], np.zeros(300,))\n",
    "        word2_rwe = rwe_5_epochs.get(train[\"kata2\"][i], np.zeros(300,))\n",
    "\n",
    "        pair_difference = np.subtract(word1_embed, word2_embed)\n",
    "        pair_addition_rwe = np.multiply(word1_rwe, word2_rwe)\n",
    "        pair_multiplication_rwe = np.multiply(word1_rwe, word2_rwe)\n",
    "\n",
    "        pair_representation = np.concatenate((pair_difference, pair_addition_rwe))\n",
    "        pair_representation = np.concatenate((pair_representation, pair_multiplication_rwe))\n",
    "        representations.append(pair_representation)\n",
    "\n",
    "    train['representation'] = representations\n",
    "    X_train = np.vstack(train['representation'])\n",
    "    y_train = train['relasi']\n",
    "\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_with_stella()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(random_state=42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_stella():\n",
    "    representations = []\n",
    "\n",
    "    word1s: list[str] = test[\"kata1\"].to_list()\n",
    "    word2s: list[str] = test[\"kata2\"].to_list()\n",
    "\n",
    "    word1s_embeddings = embedding_model.encode(word1s, batch_size=256, show_progress_bar=True)\n",
    "    word2s_embeddings = embedding_model.encode(word2s, batch_size=256, show_progress_bar=True)\n",
    "\n",
    "    for i in range(len(test)):\n",
    "\n",
    "        word1_embed = word1s_embeddings[i]\n",
    "        word2_embed = word2s_embeddings[i]\n",
    "\n",
    "        pair_difference = np.subtract(word1_embed, word2_embed)\n",
    "        representations.append(pair_difference)\n",
    "\n",
    "    test['representation'] = representations\n",
    "    X_test = np.vstack(test['representation'])\n",
    "    y_test = test['relasi']\n",
    "\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_rwe():\n",
    "    representations = []\n",
    "    for i in range(len(test)):\n",
    "        word1_embedding = ft.get_word_vector(test[\"kata1\"][i])\n",
    "        word2_embedding = ft.get_word_vector(test[\"kata2\"][i])\n",
    "\n",
    "        word1_rwe = rwe_5_epochs.get(test[\"kata1\"][i], np.zeros(300,))\n",
    "        word2_rwe = rwe_5_epochs.get(test[\"kata2\"][i], np.zeros(300,))\n",
    "\n",
    "        pair_difference_ft = np.subtract(word1_embedding, word2_embedding)\n",
    "        pair_addition_rwe = np.multiply(word1_rwe, word2_rwe)\n",
    "        # pair_multiplication_rwe = np.multiply(word1_rwe, word2_rwe)\n",
    "\n",
    "        pair_representation = np.concatenate((pair_difference_ft, pair_addition_rwe))\n",
    "        # pair_representation = np.concatenate((pair_representation, pair_multiplication_rwe))\n",
    "\n",
    "        representations.append(pair_representation)\n",
    "\n",
    "    test['representation'] = representations\n",
    "    X_test = np.vstack(test['representation'])\n",
    "    y_test = test['relasi']\n",
    "\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_ft():\n",
    "    representations = []\n",
    "    for i in range(len(test)):\n",
    "        word1_embedding = ft.get_word_vector(test[\"kata1\"][i])\n",
    "        word2_embedding = ft.get_word_vector(test[\"kata2\"][i])\n",
    "        pair_difference_ft = np.subtract(word1_embedding, word2_embedding)\n",
    "        representations.append(pair_difference_ft)\n",
    "\n",
    "    test['representation'] = representations\n",
    "    X_test = np.vstack(test['representation'])\n",
    "    y_test = test['relasi']\n",
    "\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_stella_final():\n",
    "    representations = []\n",
    "\n",
    "    word1s: list[str] = test[\"kata1\"].to_list()\n",
    "    word2s: list[str] = test[\"kata2\"].to_list()\n",
    "\n",
    "    word1s_embeddings = embedding_model.encode(word1s, batch_size=256, show_progress_bar=True)\n",
    "    word2s_embeddings = embedding_model.encode(word2s, batch_size=256, show_progress_bar=True)\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        word1_embed = word1s_embeddings[i]\n",
    "        word2_embed = word2s_embeddings[i]\n",
    "        word1_rwe = rwe_5_epochs.get(test[\"kata1\"][i], np.zeros(300,))\n",
    "        word2_rwe = rwe_5_epochs.get(test[\"kata2\"][i], np.zeros(300,))\n",
    "\n",
    "        pair_difference = np.subtract(word1_embed, word2_embed)\n",
    "        pair_addition_rwe = np.multiply(word1_rwe, word2_rwe)\n",
    "        pair_multiplication_rwe = np.multiply(word1_rwe, word2_rwe)\n",
    "\n",
    "        pair_representation = np.concatenate((pair_difference, pair_addition_rwe))\n",
    "        pair_representation = np.concatenate((pair_representation, pair_multiplication_rwe))\n",
    "        representations.append(pair_representation)\n",
    "\n",
    "    test['representation'] = representations\n",
    "    X_test = np.vstack(test['representation'])\n",
    "    y_test = test['relasi']\n",
    "\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test_with_stella()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X_test)\n",
    "sum = 0\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i] == y_test[i]:\n",
    "        sum += 1\n",
    "print(sum/len(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
